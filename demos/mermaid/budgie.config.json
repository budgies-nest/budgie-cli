{
  "model": "ai/qwen2.5:latest",
  "temperature": 0.8,
  "baseURL": "http://localhost:12434/engines/llama.cpp/v1"
}